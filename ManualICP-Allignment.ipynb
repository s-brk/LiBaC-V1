{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import open3d as o3d\n",
    "import numpy as np\n",
    "import copy\n",
    "import time\n",
    "import tempfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def draw_registration_result(source, target, transformation):\n",
    "    source_temp = copy.deepcopy(source)\n",
    "    target_temp = copy.deepcopy(target)\n",
    "    source_temp.paint_uniform_color([1, 0.706, 0])\n",
    "    target_temp.paint_uniform_color([0, 0.651, 0.929])\n",
    "    source_temp.transform(transformation)\n",
    "    o3d.visualization.draw_geometries([source_temp, target_temp])\n",
    "\n",
    "def save_registration_result(source, transformation):\n",
    "    source_temp = copy.deepcopy(source)\n",
    "    temp_file = tempfile.NamedTemporaryFile(suffix=\".ply\", delete=False)\n",
    "    registered = source_temp.transform(transformation)\n",
    "    o3d.io.write_point_cloud(temp_file.name , registered, write_ascii=True)\n",
    "    return temp_file.name\n",
    "    \n",
    "\n",
    "\n",
    "def prepare_data(source_path, target_path):\n",
    "    pcd_data = o3d.data.DemoICPPointClouds()\n",
    "    source = o3d.io.read_point_cloud(source_path)\n",
    "    target = o3d.io.read_point_cloud(target_path)\n",
    "    print(\"Visualization of two point clouds before manual alignment\")\n",
    "    draw_registration_result(source, target, np.identity(4))\n",
    "    return source, target\n",
    "\n",
    "\n",
    "def pick_points(pcd):\n",
    "    print(\"\")\n",
    "    print(\n",
    "        \"1) Please pick at least three correspondences using [shift + left click]\"\n",
    "    )\n",
    "    print(\"   Press [shift + right click] to undo point picking\")\n",
    "    print(\"2) After picking points, press 'Q' to close the window\")\n",
    "    vis = o3d.visualization.VisualizerWithEditing()\n",
    "    vis.create_window()\n",
    "    vis.add_geometry(pcd)\n",
    "    vis.run()  # user picks points\n",
    "    vis.destroy_window()\n",
    "    print(\"\")\n",
    "    return vis.get_picked_points()\n",
    "\n",
    "def scalefactor_from_correspondencies(source_point_coordinates, target_point_coordinates):\n",
    "\n",
    "    def dist(p1,p2):\n",
    "        \n",
    "        # Compute Euclidean distances between corresponding points\n",
    "        distances = np.linalg.norm(p1 - p2, axis=1)\n",
    "        \n",
    "        # Return the average distance\n",
    "        return np.mean(distances)\n",
    "    \n",
    "   \n",
    "    source_points = np.asarray(source_point_coordinates)\n",
    "    target_points = np.asarray(target_point_coordinates)\n",
    "\n",
    "\n",
    "    scale_factor = dist(source_points,target_points)\n",
    "    center = np.mean(source_point_coordinates, axis=0)\n",
    "\n",
    "\n",
    "    print(\"Type of input: \", type(source_point_coordinates))\n",
    "    print(\"Source Coordinates Listed\")\n",
    "    for corr in source_point_coordinates: print(corr)\n",
    "    \n",
    "    print(\"Target Coordinates Listed\")\n",
    "    for corr in target_point_coordinates: print(corr)\n",
    "\n",
    "    return scale_factor, center\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def register_via_correspondences(source, target, source_points, target_points):\n",
    "    corr = np.zeros((len(source_points), 2))\n",
    "    corr[:, 0] = source_points\n",
    "    corr[:, 1] = target_points\n",
    "\n",
    "    ## Verrechung skalierung\n",
    "\n",
    "    # die transformationsmatrix, die Cloudcompare errechnet lautet:\n",
    "\n",
    "    # [ -4.753,  1.162, -9.471, 3.797],\n",
    "    # [ 3.121,  10.188, -0.316, -12.449],\n",
    "    # [ 9.017, -2.914, -4,882, -12.342], \n",
    "    # [ 0.000, 0.000, 0.000, 1.000] \n",
    "\n",
    "    # darin ist die skalierung vom factor 10.6597 integriert\n",
    "   \n",
    "    #Rescaling the lidar to the size of the Gaussian\n",
    "    # source_point_coordinates = [np.asarray(source.points)[i] for i in source_points]\n",
    "    # target_point_coordinates = [np.asarray(target.points)[i] for i in target_points]\n",
    "\n",
    "\n",
    "\n",
    "    #scale_factor, center = scalefactor_from_correspondencies(source_point_coordinates, target_point_coordinates)\n",
    "\n",
    "    #scaled_source = scale_factor * (source - center) + center\n",
    "\n",
    "\n",
    "    # estimate rough transformation using correspondences\n",
    "    print(\"Compute a rough transform using the correspondences given by user\")\n",
    "    p2p = o3d.pipelines.registration.TransformationEstimationPointToPoint()\n",
    "    trans_init = p2p.compute_transformation(source, target,\n",
    "                                            o3d.utility.Vector2iVector(corr))\n",
    "    \n",
    "    #override trans init with transform from cloud compare to show if it is working\n",
    "    trans_init = np.array([\n",
    "        [-4.753,  1.162, -9.471,  3.797],\n",
    "        [ 3.121, 10.188, -0.316, -12.449],\n",
    "        [ 9.017, -2.914, -4.882, -12.342],\n",
    "        [ 0.000,  0.000,  0.000,   1.000]\n",
    "    ])\n",
    "\n",
    "    \n",
    "    # point-to-point ICP for refinement\n",
    "    print(\"Perform point-to-point ICP refinement\")\n",
    "    threshold = 0.3  # 3cm distance threshold\n",
    "    reg_p2p = o3d.pipelines.registration.registration_icp(\n",
    "        source, target, threshold, trans_init,\n",
    "        o3d.pipelines.registration.TransformationEstimationPointToPoint())\n",
    "    temp_registration = save_registration_result(source, reg_p2p.transformation)\n",
    "    draw_registration_result(source, target, reg_p2p.transformation)\n",
    "    return temp_registration\n",
    "\n",
    "def downsample_point_cloud(pcd, voxel_size):\n",
    "    \n",
    "    print(\":: Downsample with a voxel size %.3f.\" % voxel_size)\n",
    "    pcd_down = pcd.voxel_down_sample(voxel_size)\n",
    "   \n",
    "    return pcd_down\n",
    "\n",
    "def demo_manual_registration():\n",
    "\n",
    "    print(\"Demo for manual ICP\")\n",
    "    pcd_data = o3d.data.DemoICPPointClouds()\n",
    "    source, target = prepare_data(pcd_data.paths[0], pcd_data.paths[2])\n",
    "\n",
    "    # pick points from two point clouds and builds correspondences\n",
    "    source_points = pick_points(source)\n",
    "    target_points = pick_points(target)\n",
    "    assert (len(source_points) >= 3 and len(target_points) >= 3)\n",
    "    assert (len(source_points) == len(target_points))\n",
    "    register_via_correspondences(source, target, source_points, target_points)\n",
    "    print(\"\")\n",
    "\n",
    "def manual_registration(lidar_path, gaussiansplat_path):\n",
    "\n",
    "    print(\"manual ICP\")\n",
    "    \n",
    "    source, target = prepare_data(lidar_path, gaussiansplat_path)\n",
    "\n",
    "    lidar_points = len(source.points)\n",
    "    gaussian_points = len(target.points)\n",
    "\n",
    "    voxel_size = (lidar_points//gaussian_points)*0.001\n",
    "    print(voxel_size)\n",
    "    source_down = downsample_point_cloud(source, voxel_size)\n",
    "\n",
    "\n",
    "\n",
    "    # pick points from two point clouds and builds correspondences\n",
    "    source_points = pick_points(source_down)\n",
    "    print(\"Type of Points: \",type(source_points))\n",
    "    picked_coordinates = [source.points[i] for i in source_points]\n",
    "    print(\"Coordinates of picked points:\")\n",
    "    for coord in picked_coordinates:\n",
    "        print(coord)\n",
    "    \n",
    "    target_points = pick_points(target)\n",
    "    assert (len(source_points) >= 3 and len(target_points) >= 3)\n",
    "    assert (len(source_points) == len(target_points))\n",
    "    registered = register_via_correspondences(source_down, target, source_points, target_points)\n",
    "    print(\"\")\n",
    "    return registered\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "manual ICP\n",
      "Visualization of two point clouds before manual alignment\n",
      "0.001\n",
      ":: Downsample with a voxel size 0.001.\n",
      "\n",
      "1) Please pick at least three correspondences using [shift + left click]\n",
      "   Press [shift + right click] to undo point picking\n",
      "2) After picking points, press 'Q' to close the window\n",
      "[Open3D INFO] Picked point #1088858 (0.87, 0.74, 1.2) to add in queue.\n",
      "[Open3D INFO] Picked point #1020462 (2.4, 0.39, 1.1) to add in queue.\n",
      "[Open3D INFO] Picked point #1106481 (0.75, -0.23, 1.2) to add in queue.\n",
      "[Open3D INFO] Picked point #721483 (2.3, -0.75, 1.1) to add in queue.\n",
      "\n",
      "Type of Points:  <class 'list'>\n",
      "Coordinates of picked points:\n",
      "[-0.99639  -0.60068   1.102815]\n",
      "[ 0.850536 -1.161605 -0.612872]\n",
      "[-3.297311  0.318845  1.108831]\n",
      "[ 3.571142 -0.562967  1.145041]\n",
      "\n",
      "1) Please pick at least three correspondences using [shift + left click]\n",
      "   Press [shift + right click] to undo point picking\n",
      "2) After picking points, press 'Q' to close the window\n",
      "[Open3D INFO] Picked point #4237 (-6.5, -1.1, 31.) to add in queue.\n",
      "[Open3D INFO] Picked point #71546 (6.7, -6.8, 15.) to add in queue.\n",
      "[Open3D INFO] Picked point #2955 (-12., -13., 28.) to add in queue.\n",
      "[Open3D INFO] Picked point #72992 (2.4, -17., 31.) to add in queue.\n",
      "\n",
      "Compute a rough transform using the correspondences given by user\n",
      "Perform point-to-point ICP refinement\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cc_pc = \"D:\\MASTERPROJEKT\\Daten\\musikzimmer\\gaussiansplat\\iteration_30000\\musikzimmer_gaussiansplat_cc.ply\"\n",
    "lidar_pc = \"D:\\MASTERPROJEKT\\Daten\\musikzimmer\\lidar\\Musikzimmer_iphone_LIDAR_v02_cc.ply\"\n",
    " \n",
    "\n",
    "cc_pc_alligned = manual_registration(lidar_pc, cc_pc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pointcloudedit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
